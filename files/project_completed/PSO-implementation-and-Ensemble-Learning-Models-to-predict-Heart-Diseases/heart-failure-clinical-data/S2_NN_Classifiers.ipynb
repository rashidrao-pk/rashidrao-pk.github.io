{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2667377d",
   "metadata": {},
   "source": [
    "# Training Module for Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79317e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64af0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plib.data import get_data,minmax_norm,data_split\n",
    "from plib.feature_selection import out_features\n",
    "from plib.p_metric import main_perf_metrics_calc\n",
    "\n",
    "#NN\n",
    "from numpy import random, dot, tanh\n",
    "from ACSO_Ensemble import rider\n",
    "\n",
    "#DNFN & Keras modules and its important APIs\n",
    "import tensorflow as tf\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,Activation, Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam as opti\n",
    "\n",
    "#from ACSO_Ensemble.FuzzyLayer import FuzzyLayer\n",
    "from ACSO_Ensemble.DefuzzyLayer import DefuzzyLayer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120cb47",
   "metadata": {},
   "source": [
    "# Read and Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0190d4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 299;  Number of columns: 13; No of missing values 0\n",
      "Shape of X_train: (299, 12)\n",
      "Shape of y_train: (299,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.833893</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>581.839465</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>38.083612</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>263358.029264</td>\n",
       "      <td>1.393880</td>\n",
       "      <td>136.625418</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>0.321070</td>\n",
       "      <td>130.260870</td>\n",
       "      <td>0.321070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.894809</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>970.287881</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>11.834841</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>97804.236869</td>\n",
       "      <td>1.034510</td>\n",
       "      <td>4.412477</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.467670</td>\n",
       "      <td>77.614208</td>\n",
       "      <td>0.467670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212500.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262000.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>303500.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>850000.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age    anaemia  creatinine_phosphokinase   diabetes  \\\n",
       "count 299.000000 299.000000                299.000000 299.000000   \n",
       "mean   60.833893   0.431438                581.839465   0.418060   \n",
       "std    11.894809   0.496107                970.287881   0.494067   \n",
       "min    40.000000   0.000000                 23.000000   0.000000   \n",
       "25%    51.000000   0.000000                116.500000   0.000000   \n",
       "50%    60.000000   0.000000                250.000000   0.000000   \n",
       "75%    70.000000   1.000000                582.000000   1.000000   \n",
       "max    95.000000   1.000000               7861.000000   1.000000   \n",
       "\n",
       "       ejection_fraction  high_blood_pressure     platelets  serum_creatinine  \\\n",
       "count         299.000000           299.000000    299.000000        299.000000   \n",
       "mean           38.083612             0.351171 263358.029264          1.393880   \n",
       "std            11.834841             0.478136  97804.236869          1.034510   \n",
       "min            14.000000             0.000000  25100.000000          0.500000   \n",
       "25%            30.000000             0.000000 212500.000000          0.900000   \n",
       "50%            38.000000             0.000000 262000.000000          1.100000   \n",
       "75%            45.000000             1.000000 303500.000000          1.400000   \n",
       "max            80.000000             1.000000 850000.000000          9.400000   \n",
       "\n",
       "       serum_sodium        sex    smoking       time  DEATH_EVENT  \n",
       "count    299.000000 299.000000 299.000000 299.000000   299.000000  \n",
       "mean     136.625418   0.648829   0.321070 130.260870     0.321070  \n",
       "std        4.412477   0.478136   0.467670  77.614208     0.467670  \n",
       "min      113.000000   0.000000   0.000000   4.000000     0.000000  \n",
       "25%      134.000000   0.000000   0.000000  73.000000     0.000000  \n",
       "50%      137.000000   1.000000   0.000000 115.000000     0.000000  \n",
       "75%      140.000000   1.000000   1.000000 203.000000     1.000000  \n",
       "max      148.000000   1.000000   1.000000 285.000000     1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train ,Y_train,train_df =get_data('./plib/dataset/heart_failure_clinical_records_dataset.csv')\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", Y_train.shape)\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9114f",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63089031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (299, 12)\n",
      "Shape of y_train: (299,)\n",
      "Classes:  2\n"
     ]
    }
   ],
   "source": [
    "X_train=minmax_norm(X_train)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", Y_train.shape)\n",
    "classes=len(np.unique(Y_train))\n",
    "print(\"Classes: \",classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79365a",
   "metadata": {},
   "source": [
    "# Split Data for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a4f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (239, 12)\n",
      "Shape of y_train: (239,)\n",
      "Shape of X_test: (60, 12)\n",
      "Shape of y_test: (60,)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xvalid, ytrain, yvalid,fold=data_split(X_train,Y_train,test_size=0.2)\n",
    "print(\"Shape of X_train:\", xtrain.shape)\n",
    "print(\"Shape of y_train:\", ytrain.shape)\n",
    "print(\"Shape of X_test:\", xvalid.shape)\n",
    "print(\"Shape of y_test:\", yvalid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd898f1",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f62e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Best (PSO): 0.2583283739826727\n",
      "Iteration: 2\n",
      "Best (PSO): 0.25539636609358657\n",
      "Iteration: 3\n",
      "Best (PSO): 0.25539636609358657\n",
      "Run Time --- 0.4922020435333252 seconds ---\n",
      "Number of Best Features:  5\n",
      "5 7\n",
      "Seleted Feature Composition:  (239, 7) (60, 7)\n",
      "You choosed worse features too.\n",
      "Shape of X_train: (239, 7)\n",
      "Shape of y_train: (239,)\n",
      "Shape of X_test: (60, 7)\n",
      "Shape of y_test: (60,)\n"
     ]
    }
   ],
   "source": [
    "opts = {'k':5, 'fold':fold, 'N':X_train.shape[0], 'T':7, 'w':0.7, 'c1':2, 'c2':2}\n",
    "x_train, x_test, y_train, y_test,b_feat= out_features(X_train,Y_train,opts,xtrain, xvalid, ytrain, yvalid)\n",
    "print (\"Number of Best Features: \",b_feat)\n",
    "\n",
    "sel_feat_ratio=60\n",
    "w=round(x_train.shape[1]*sel_feat_ratio/100)\n",
    "print(b_feat,w)\n",
    "if w > b_feat:\n",
    "    x_train=x_train[:,0:  w]\n",
    "    x_test=x_test[:,0:w]\n",
    "    print(\"Seleted Feature Composition: \",x_train.shape,x_test.shape)\n",
    "    print('You choosed worse features too.')\n",
    "else:\n",
    "    x_train=x_train[:,0:  w]\n",
    "    x_test=x_test[:,0:w]\n",
    "    print(\"Seleted Feature Composition: \",x_train.shape,x_test.shape)\n",
    "    \n",
    "print(\"Shape of X_train:\", x_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", x_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30eb1d1",
   "metadata": {},
   "source": [
    "# Defining Performance Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9002eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_table=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da30bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432731cd",
   "metadata": {},
   "source": [
    "# DNFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11806bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.6109\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.6109\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.6109\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.6109\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.6109\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.6109\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.6109\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.6109\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 0.6109\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.6109\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0715 - accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, sensitivity, specificity, Precision, F1-score\n",
      "(0.9344262295081968, 0.95, 0.9047619047619048, 0.95, 0.9500000000000001)\n"
     ]
    }
   ],
   "source": [
    "#DNFN\n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT']='1'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "nc = 2\n",
    "\n",
    "\n",
    "def classify(x_train, x_test, y_train):\n",
    "\n",
    "    model.add(Dense(5, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(units=2))\n",
    "    model.add(DefuzzyLayer(1))\n",
    "    model.compile(metrics=['accuracy'], optimizer=opti(), loss=tf.keras.losses.MSE)\n",
    "    model.fit(x_train, y_train, batch_size=50, epochs=10, verbose=1)\n",
    "    plot_model(model, to_file='model_DNFN1.jpg', show_shapes=True, dpi=400)\n",
    "    return model\n",
    "\n",
    "y_pred=classify(x_train, x_test, y_train).predict(x_test)\n",
    "score=model.evaluate(x_test, y_test)\n",
    "measures =main_perf_metrics_calc(y_test, y_pred.round(),classes)\n",
    "print(measures)\n",
    "measures_table['DNFN'] = measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372b178",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9491fc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEGCAYAAADmLRl+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW/ElEQVR4nO3de5QcZZnH8e9vJhMCJARCAgSIEgTBgBIw3FeMKArqCrisih5FhUVUBG/rAdddFXc93llXATdCDrgiCAsIKnIR0IirkgsRSBBRDJAQCJMQQu4z3c/+UTXQCcl01UxfqmZ+H0+ddFV3v/VkBp+871vvRRGBmVmZdbQ7ADOzwXIiM7PScyIzs9JzIjOz0nMiM7PSG9HuAGqNH9cZe03qancYlsOyysh2h2A5rFiyntXPbNRgynjT67aP5SsqmT47974Nt0bE8YO5XxaFSmR7TerinlsntTsMy+Gilf59lcnXT5kz6DK6V1T4w617Zvps18S/jh/0DTMoVCIzszIIKlFtdxCbcCIzs1wCqFKsgfTu7Dez3KoZ/9cfSaMk3SPpj5IWSPpien2ypD9I+oukH0uq2xHrRGZmuQRBT1QzHXVsAI6NiIOAqcDxko4AvgpcGBH7AM8Ap9cryInMzHIJoEJkOvotJ7E6Pe1KjwCOBf43vX4FcFK9mJzIzCy3KpHpAMZLmlNznFlbjqROSfOBZcDtwF+BlRHRm35kMbBHvXjc2W9muQRQyb5qTndETNtqWREVYKqkHYEbgP0HEpMTmZnl1ujBFxGxUtJdwJHAjpJGpLWyPYEl9b7vpqWZ5RIZ+8fq9ZFJmpDWxJC0LXAc8CBwF3BK+rHTgBvrxeQamZnlEgE9jRlGNhG4QlInSaXqmoj4maSFwNWS/h24F7isXkFOZGaWk6gwqOmaAETEfcDBW7j+CHBYnrKcyMwslwCqxRrY70RmZvk1okbWSE5kZpZLMiDWiczMSiyAnijWgAcnMjPLJRCVgo3cciIzs9yq4aalmZWY+8jMbAgQFfeRmVmZJSvEOpGZWYlFiI3R2e4wNuFEZma5Vd1HZmZllnT2u2lpZqXmzn4zKzl39pvZkFDxgFgzK7NA9ESxUkexojGzwnNnv5mVXiA3Lc2s/NzZb2alFoGHX5hZuSWd/Z6iZGYl585+Myu1QF5Y0czKzzUyMyu1ZF9LJzIzK7XG7DTeSMVKq2ZWeMl2cJ2Zjv5ImiTpLkkLJS2QdG56/QuSlkianx5vrheTa2RmlkuEGtW07AU+FRHzJI0B5kq6PX3vwoj4RtaCnMjMLLdGDIiNiKXA0vT1c5IeBPYYSFluWppZLsl6ZMp0AOMlzak5ztxSmZL2Ag4G/pBeOlvSfZJmStqpXkyukZlZTrlWiO2OiGn9liaNBq4DPh4RqyRdAnyJJGd+Cfgm8MH+ynAiM7NckuEXjXlqKamLJIldGRHXA0TEUzXvfx/4Wb1ynMjMLJdGzbWUJOAy4MGI+FbN9Ylp/xnAycAD9cpyIjOz3Bq0jM/RwHuB+yXNT699FjhV0lSSyt8i4EP1CnIiM7NckmV8Bt+0jIi7YYsja2/OW5YTmZnl5knjZlZqyeoXxRq55URmZrkkU5ScyIasjevFp96+Dz0bO6j0wmve8izv++cnuXHmeG64dAJLF23DNfffz9idK+0O1VLrlnYw7/zRbOgWErz0HRvY+73rAXjkh6NYdNUo1BHs8toeDvj02jZHWxTDrEYm6Xjg20AncGlEfKWZ92u3rm2Cr137V7bdvkpvD3zypH059NhVHHDoGg4/bhWf+Yd92h2ibUYjggM+s4Ydp1ToXQO/PmVHJhzZw4bl4sk7u3jtDSvpHAkblherT6jdqgVb/aJpiUxSJ3ARcBywGJgt6aaIWNise7abBNtuXwWgt0dUepJ/5fd55bo2R2ZbM2pCMGpCUkMesT2M2bvCumUdPHbtNux7xno6Ryaf22bnaGOUxdKop5aN1Mz64WHAXyLikYjYCFwNnNjE+xVCpQIffsN+vPNVB3LwMc+x/yFujpTF2iUdPPtgJzu9qpfVizpZPncEs965A7993w48c3+xNttot2p0ZDpapZl32gN4vOZ8MVuY2S7pzL4JpU8vL3/fUWcnXPLLh7hy7kIemr8di/40qt0hWQa9a2D2uWM44Py1dI0OogI9z4rXXL2KKZ9ey9xPjiFcKQNeWLM/y9Eqbe+xi4gZETEtIqZN2Hno/Ks3emyFg45azey7xrQ7FKuj2gOzPz6GPd+6gd2P2wjAqN2qTDxuIxLs9Kpe6ICNzxSrOdUuAfRGR6ajVZp5pyXApJrzPdNrQ9bK5Z2sfjZJxhvWiXmzxjBpnw1tjsr6EwHz/3U0Y/au8LL3r3/++sRjN9J9TxcAqxd1UO2BkTu5StanaE3LZj61nA3sK2kySQJ7F/DuJt6v7VY81cU3zn0J1aqoVuGYv1/JEcet4ieXjufaS3ZhxbIuznrD/hx27Co+8c3H6xdoTbdi3ggW37QNY17ey69OHgvAKz6+lpe8fQP3fm40d71tLB1dcPCXVyNXyBItbjZm0bREFhG9ks4GbiUZfjEzIhY0635FsPeU9Vx8+59fdP2kM7o56YzuNkRk9ez86l7etnD5Ft979ddWtziacuhbWLFImjqOLCJuZgATQM2s2IZNjczMhqZGLqzYKE5kZpZLIHqrbR/wsAknMjPLbVj1kZnZEBRuWppZybmPzMyGBCcyMyu1QFTc2W9mZefOfjMrtXBnv5kNBeFEZmblNowmjZvZ0OUamZmVWgRUqsVKZMV6hmpmpVBFmY7+SJok6S5JCyUtkHRuen2cpNslPZz+uVO9eJzIzCyXIGlaZjnq6AU+FRFTgCOAj0qaApwH3BER+wJ3pOf9ciIzs5was/lIRCyNiHnp6+eAB0k2KDoRuCL92BXASfUich+ZmeXW6B2lJO0FHAz8Adg1Ipambz0J7Frv+05kZpZbjqeW4yXNqTmfEREzaj8gaTRwHfDxiFilms0RIiIk1U2bTmRmlkvy1DJzr1R3REzb2puSukiS2JURcX16+SlJEyNiqaSJwLJ6N3EfmZnlFpHt6I+SqtdlwIMR8a2at24CTktfnwbcWC8e18jMLLcGDYg9GngvcL+k+em1zwJfAa6RdDrwKPCOegU5kZlZLkGmoRX1y4m4G7Y62Oz1ecpyIjOz3Iq257oTmZnlExAFm6LkRGZmuXnSuJmVXqMHxA7WVhOZpO/QT1M4Is5pSkRmVmh9cy2LpL8a2Zx+3jOz4SqAsiSyiLii9lzSdhGxtvkhmVnRFa1pWXdkv6QjJS0E/pSeHyTp4qZHZmYFJaKa7WiVLFOU/hN4E7AcICL+CBzTxJjMrOgi49EimZ5aRsTjtTPSgUpzwjGzwotydfb3eVzSUUCkM9XPJVkAzcyGq7L1kQFnAR8lWbnxCWBqem5mw5YyHq1Rt0YWEd3Ae1oQi5mVRbXdAWwqy1PLvSX9VNLTkpZJulHS3q0IzswKqG8cWZajRbI0LX8EXANMBHYHrgWuamZQZlZsjVhYsZGyJLLtIuJ/IqI3PX4IjGp2YGZWYGUZfiFpXPryF5LOA64mCe2dwM0tiM3MiqpEwy/mkiSuvog/VPNeAOc3KygzK7b6+xq1Vn9zLSe3MhAzK4kQlHFhRUkHAlOo6RuLiB80KygzK7iy1Mj6SPo8MJ0kkd0MnADcDTiRmQ1XBUtkWZ5ankKyo8mTEfEB4CBgbFOjMrNiK8tTyxrrIqIqqVfSDiS7/k5qclxmVlRlWlixxhxJOwLfJ3mSuRr4XTODMrNiK81Tyz4R8ZH05fck3QLsEBH3NTcsMyu0siQySYf0915EzGtOSGZWdGWqkX2zn/cCOLbBsfDwn3bkLUef2OhirYl6//Zou0OwHFZGg3aAbFAfmaSZwFuBZRFxYHrtC8A/AU+nH/tsRPQ7m6i/AbGva0ikZja0NPaJ5OXAd3nxcK4LI+IbWQvJMvzCzGxTDRp+ERGzgBWDDceJzMxyUzXbMQhnS7pP0kxJO9X7sBOZmeWXvUY2XtKcmuPMDKVfAryMZFn9pfTfXw9km6IkkqWu946ICyS9BNgtIu7JEJCZDTGKXE8tuyNiWp7yI+Kp5+8lfR/4Wb3vZKmRXQwcCZyanj8HXJQnMDMbYpq41LWkiTWnJwMP1PtOlmexh0fEIZLuBYiIZySNHFCEZjY0NOippaSrSBalGC9pMfB5YLqkqeldFrHpWohblCWR9UjqTAtF0gQKt4eKmbVSowbERsSpW7h8Wd5ysiSy/wJuAHaR9B8kq2F8Lu+NzGyIiEE/kWy4LHMtr5Q0l2QpHwEnRYR3Gjcbzko0RQmA9CnlWuCntdci4rFmBmZmBVa2RAb8nBc2IRkFTAYeAg5oYlxmVmBlmjQOQES8svY8XRXjI1v5uJlZy+WeCh8R8yQd3oxgzKwkylYjk/TJmtMO4BDgiaZFZGbFVsanlsCYmte9JH1m1zUnHDMrhTLVyNKBsGMi4tMtisfMCk6UqLNf0oiI6JV0dCsDMrMSKEsiA+4h6Q+bL+km4FpgTd+bEXF9k2MzsyLKt/pFS2TpIxsFLCdZo79vPFkATmRmw1WJOvt3SZ9YPsALCaxPwfKxmbVSmWpkncBoNk1gfQr21zCzlipYBugvkS2NiAtaFomZlUNjd1FqiP4SWWM2rjOzIadMTcvXtywKMyuXsiSyiBj0XnNmNjSVcYqSmdkLStZHZmb2IqJ4HehOZGaWn2tkZlZ2ZXpqaWa2ZU5kZlZqJV1Y0cxsU66RmVnZFa2PrKPdAZhZCUXGow5JMyUtk/RAzbVxkm6X9HD65071ynEiM7PcFNmODC4Hjt/s2nnAHRGxL3BHet4vJzIzyydIFlbMctQrKmIWsPl0yBOBK9LXVwAn1SvHfWRmlksLNh/ZNSKWpq+fBHat9wUnMjPLL3siGy9pTs35jIiYkfk2ESHVT5tOZGaWmyJzJuuOiGk5i39K0sSIWCppIrCs3hfcR2Zm+WR9Yjnw5udNwGnp69OAG+t9wYnMzHJr1FNLSVcBvwP2k7RY0unAV4DjJD0MvCE975eblmaWW6OmKEXEqVt5K9cK1U5kZpZfwUb2O5GZWT4l3WnczGxTTmRmVmYtGBCbmxOZmeWmarEymROZmeXjXZSGl66RFb560W/p6qrSOSL47V0TufKy/dsdlvVj2vRVnPWlJ+jsCH5x1Tiu+W7daX7D0rBZIVbSTOCtwLKIOLBZ9ymyno0dfPaco1i/bgSdnVW+fsndzPn9Ljy0YFy7Q7Mt6OgIPvrlJZz/rr3pXtrFd25+mN/fOpbHHh7V7tCKp2A1smaO7L+cF68zNMyI9euSfytGjEhqZUTRdgS0PvsdvJYnFo3kyce2obeng1/duCNHvunZdodVSA1cj6whmlYji4hZkvZqVvll0dERfHvmr5m4xxp+fv1kHlpYd7FLa5Odd+vh6SdGPn/evbSL/Q9Z28aICiqA7JPGW6Ltcy0lnSlpjqQ5G6tD7z+aalV87P3TOe3kN/LyKc/w0smr2h2S2aCpmu1olbYnsoiYERHTImLayI7t2h1O06xZ3cV988bz6iPqrkhibbL8yS4m7L7x+fPxE3voXtrVxoiKqW8cWZGalm1PZEPZDjtuYPvRPQCMHFlh6qFP8/ijo9sclW3NQ/O3Y4/JG9l10gZGdFWZfuJKfn/b2HaHVTwR2Y8W8fCLJhq383o++bl76egI1AF337k7s/9vt3aHZVtRrYiL/mUPvvyjR+johNuuHsejf/YTyy0ZNiP703WGppMsdbsY+HxEXNas+xXRor+O5ZwPTG93GJbD7Dt3YPadO7Q7jOIbLomsn3WGzKzkhk2NzMyGqAAqxcpkTmRmlptrZGZWfgUbEOtEZma5uUZmZuXmZXzMrOwEyJ39ZlZ2OXYabwknMjPLx01LMyu/1s6jzMKJzMxy81NLMys/18jMrNSicU8tJS0CngMqQG9ETBtIOU5kZpZfYytkr4uI7sEU4ERmZrkVbfiFV4g1s/yyrxA7vm9PjvQ4c/OSgNskzd3Ce5m5RmZm+QSQfWOR7jr9Xn8XEUsk7QLcLulPETErb0iukZlZLiJQZDvqiYgl6Z/LgBuAwwYSkxOZmeVXrWY7+iFpe0lj+l4DbwQeGEg4blqaWT75mpb92RW4QRIkuehHEXHLQApyIjOz3Brx1DIiHgEOGnw0TmRmNhAFG37hRGZmOXnSuJmVnXdRMrOhoGgj+53IzCw/JzIzK7UAqk5kZlZq7uw3s6HAiczMSi2ASmOG9jeKE5mZ5RQQTmRmVnZuWppZqfmppZkNCa6RmVnpOZGZWalFQKXS7ig24URmZvm5RmZmpedEZmblFn5qaWYlFxAeEGtmpecpSmZWahF1t3prNScyM8vPnf1mVnbhGpmZlZsXVjSzsvOkcTMruwCiYFOUOtodgJmVTKQLK2Y56pB0vKSHJP1F0nkDDck1MjPLLRrQtJTUCVwEHAcsBmZLuikiFuYtyzUyM8uvMTWyw4C/RMQjEbERuBo4cSDhKAr09EHS08Cj7Y6jCcYD3e0OwnIZqr+zl0bEhMEUIOkWkp9PFqOA9TXnMyJiRlrOKcDxEXFGev5e4PCIODtvTIVqWg72B1xUkuZExLR2x2HZ+Xe2dRFxfLtj2JyblmbWLkuASTXne6bXcnMiM7N2mQ3sK2mypJHAu4CbBlJQoZqWQ9iMdgdgufl31mQR0SvpbOBWoBOYGRELBlJWoTr7zcwGwk1LMys9JzIzKz0nsiZq1PQLax1JMyUtk/RAu2Ox7JzImqRm+sUJwBTgVElT2huVZXA5ULhxUtY/J7Lmadj0C2udiJgFrGh3HJaPE1nz7AE8XnO+OL1mZg3mRGZmpedE1jwNm35hZv1zImuehk2/MLP+OZE1SUT0An3TLx4Erhno9AtrHUlXAb8D9pO0WNLp7Y7J6vMUJTMrPdfIzKz0nMjMrPScyMys9JzIzKz0nMjMrPScyEpEUkXSfEkPSLpW0naDKOvydBcbJF3a34R2SdMlHTWAeyyS9KLddrZ2fbPPrM55ry9I+nTeGG1ocCIrl3URMTUiDgQ2AmfVvilpQEuXR8QZdTZFnQ7kTmRmreJEVl6/AfZJa0u/kXQTsFBSp6SvS5ot6T5JHwJQ4rvp+mi/BHbpK0jSryRNS18fL2mepD9KukPSXiQJ8xNpbfA1kiZIui69x2xJR6ff3VnSbZIWSLoUUL2/hKSfSJqbfufMzd67ML1+h6QJ6bWXSbol/c5vJO3fkJ+mlZo3HymhtOZ1AnBLeukQ4MCI+FuaDJ6NiEMlbQP8VtJtwMHAfiRro+0KLARmblbuBOD7wDFpWeMiYoWk7wGrI+Ib6ed+BFwYEXdLegnJ7IVXAJ8H7o6ICyS9BcgyKv6D6T22BWZLui4ilgPbA3Mi4hOS/i0t+2ySTUHOioiHJR0OXAwcO4Afow0hTmTlsq2k+enr3wCXkTT57omIv6XX3wi8qq//CxgL7AscA1wVERXgCUl3bqH8I4BZfWVFxNbW5XoDMEV6vsK1g6TR6T3enn7355KeyfB3OkfSyenrSWmsy4Eq8OP0+g+B69N7HAVcW3PvbTLcw4Y4J7JyWRcRU2svpP+HXlN7CfhYRNy62efe3MA4OoAjImL9FmLJTNJ0kqR4ZESslfQrYNRWPh7pfVdu/jMwcx/Z0HMr8GFJXQCSXi5pe2AW8M60D20i8LotfPf3wDGSJqffHZdefw4YU/O524CP9Z1Impq+nAW8O712ArBTnVjHAs+kSWx/khphnw6gr1b5bpIm6yrgb5L+Mb2HJB1U5x42DDiRDT2XkvR/zUs30Phvkpr3DcDD6Xs/IFnhYRMR8TRwJkkz7o+80LT7KXByX2c/cA4wLX2YsJAXnp5+kSQRLiBpYj5WJ9ZbgBGSHgS+QpJI+6wBDkv/DscCF6TX3wOcnsa3AC8fbnj1CzMbAlwjM7PScyIzs9JzIjOz0nMiM7PScyIzs9JzIjOz0nMiM7PS+3+ZbUQyIO8yWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, sensitivity, specificity, Precision, F1-score\n",
      "(0.4449760765550239, 0.5166666666666667, 0.34831460674157305, 0.5166666666666667, 0.5166666666666667)\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        # Using seed to make sure it'll\n",
    "        # generate same weights in every run\n",
    "        random.seed(1)\n",
    "\n",
    "        # 3x1 Weight matrix\n",
    "        self.weight_matrix = 2 * random.random((dim, 1)) - 1\n",
    "\n",
    "    # tanh as activation function\n",
    "    def tanh(self, x):\n",
    "        return tanh(x)\n",
    "\n",
    "        # derivative of tanh function.\n",
    "\n",
    "    # Needed to calculate the gradients.\n",
    "    def tanh_derivative(self, x):\n",
    "        return 1.0 - tanh(x) ** 2\n",
    "\n",
    "    # forward propagation\n",
    "    def forward_propagation(self, inputs):\n",
    "        return self.tanh(dot(inputs, self.weight_matrix)), random.uniform(0, 1, size=len(inputs))\n",
    "\n",
    "    # training the neural network.\n",
    "    def train(self, train_inputs, train_outputs,\n",
    "              num_train_iterations):\n",
    "        # Number of iterations we want to\n",
    "        # perform for this set of input.\n",
    "        for iteration in range(num_train_iterations):\n",
    "            output, x = self.forward_propagation(train_inputs)\n",
    "\n",
    "            # Calculate the error in the output.\n",
    "            error = train_outputs - output\n",
    "\n",
    "            # multiply the error by input and then\n",
    "            # by gradient of tanh funtion to calculate\n",
    "            # the adjustment needs to be made in weights\n",
    "            adjustment = dot(train_inputs.T, error *\n",
    "                             self.tanh_derivative(output))\n",
    "\n",
    "            # Adjust the weight matrix\n",
    "            self.weight_matrix += adjustment * rider.Alg()\n",
    "\n",
    "\n",
    "def classify(x_train, x_test, y_train):\n",
    "    nc = 2\n",
    "    train_outputs = np.array([y_train]).T\n",
    "    neural_network = NeuralNetwork(len(x_train[0]))\n",
    "    neural_network.train(np.array(x_train), train_outputs, 10)\n",
    "\n",
    "    # Test the neural network with a new situation.\n",
    "    x, pred = neural_network.forward_propagation(x_test)\n",
    "\n",
    "    predict = []\n",
    "    for i in range(len(pred)):\n",
    "        predict.append(np.abs(np.round(pred[i])))\n",
    "    if len(np.unique(predict)) != nc:\n",
    "        for i in range(nc): predict[i]=i\n",
    "    return predict\n",
    "\n",
    "y_pred=classify(x_train, x_test, y_train)\n",
    "\n",
    "\n",
    "measures =main_perf_metrics_calc(y_test, y_pred,classes)\n",
    "print(measures)\n",
    "measures_table['NN'] = measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d6c93",
   "metadata": {},
   "source": [
    "# Ride NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d686b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 5s 315ms/step - loss: 0.8715 - binary_accuracy: 0.5146 - val_loss: 0.8252 - val_binary_accuracy: 0.9500\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.7934 - binary_accuracy: 0.6192 - val_loss: 0.7315 - val_binary_accuracy: 0.9500\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.6390 - binary_accuracy: 0.7908 - val_loss: 0.3909 - val_binary_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.4258 - binary_accuracy: 0.8996 - val_loss: 0.4544 - val_binary_accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.3067 - binary_accuracy: 0.9603 - val_loss: 0.4872 - val_binary_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.2451 - binary_accuracy: 0.9895 - val_loss: 0.9839 - val_binary_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.2289 - binary_accuracy: 0.9770 - val_loss: 0.9337 - val_binary_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.2527 - binary_accuracy: 0.9728 - val_loss: 0.7347 - val_binary_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.2315 - binary_accuracy: 0.9833 - val_loss: 1.1964 - val_binary_accuracy: 0.0500\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.2284 - binary_accuracy: 0.9812 - val_loss: 2.1259 - val_binary_accuracy: 0.0500\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "2/2 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, sensitivity, specificity, Precision, F1-score\n",
      "(0.9130434782608695, 0.9333333333333333, 0.875, 0.9333333333333333, 0.9333333333333333)\n"
     ]
    }
   ],
   "source": [
    "nc = 2\n",
    "def classify(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    # Setting Training Hyperparameters\n",
    "    batch_size = 128  # original ResNet paper uses batch_size = 128 for training\n",
    "    epochs = 10\n",
    "    data_augmentation = False\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    # Data Preprocessing\n",
    "    subtract_pixel_mean = True\n",
    "    n = 3\n",
    "\n",
    "    # Select ResNet Version\n",
    "    version = 1\n",
    "\n",
    "    # Computed depth of\n",
    "    if version == 1:\n",
    "        depth = n * 6 + 2\n",
    "    elif version == 2:\n",
    "        depth = n * 9 + 2\n",
    "\n",
    "    # Model name, depth and version\n",
    "    model_type = 'ResNet % dv % d' % (depth, version)\n",
    "\n",
    "    xt = len(x_train)\n",
    "    yt = len(x_test)\n",
    "\n",
    "    x_train = np.resize(x_train, (xt, 32, 32, 3))\n",
    "    x_test = np.resize(x_test, (yt, 32, 32, 3))\n",
    "    # Input image dimensions.\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_train = y_train.astype('int')\n",
    "    # Normalize data.\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    y_test = y_test.astype('int')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    # Setting LR for different number of Epochs\n",
    "    def lr_schedule(epoch):\n",
    "        lr = 0.1\n",
    "        if epoch > 180:\n",
    "            lr *= 0.5e-3\n",
    "        elif epoch > 160:\n",
    "            lr *= 1e-3\n",
    "        elif epoch > 120:\n",
    "            lr *= 1e-2\n",
    "        elif epoch > 80:\n",
    "            lr *= 1e-1\n",
    "        return lr\n",
    "\n",
    "    # Basic ResNet Building Block\n",
    "    def resnet_layer(inputs,\n",
    "                     num_filters=16,\n",
    "                     kernel_size=3,\n",
    "                     strides=1,\n",
    "                     activation='relu', batch_normalization=True):\n",
    "        conv = Conv2D(num_filters,\n",
    "                      kernel_size=kernel_size,\n",
    "                      strides=strides,\n",
    "                      padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(1e-4))\n",
    "\n",
    "        x = inputs\n",
    "        if conv:\n",
    "            x = conv(x)\n",
    "            if batch_normalization:\n",
    "                x = BatchNormalization( )(x)\n",
    "            if activation is not None:\n",
    "                x = Activation(activation)(x)\n",
    "        else:\n",
    "            if batch_normalization:\n",
    "                x = BatchNormalization( )(x)\n",
    "            if activation is not None:\n",
    "                x = Activation(activation)(x)\n",
    "            x = conv(x)\n",
    "        return x\n",
    "\n",
    "    #\n",
    "    def resnet_v1(input_shape, depth, num_classes=num_classes):\n",
    "        if (depth - 2) % 6 != 0:\n",
    "            raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])')\n",
    "        # Start model definition.\n",
    "        num_filters = 16\n",
    "        num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = resnet_layer(inputs=inputs)\n",
    "\n",
    "        # Instantiate the stack of residual units\n",
    "        for stack in range(3):\n",
    "            for res_block in range(num_res_blocks):\n",
    "                strides = 1\n",
    "                if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                    strides = 2  # downsample\n",
    "                y = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 strides=strides)\n",
    "                y = resnet_layer(inputs=y,\n",
    "                                 num_filters=num_filters,\n",
    "                                 activation=None)\n",
    "                if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                    # linear projection residual shortcut connection to match\n",
    "                    # changed dims\n",
    "                    x = resnet_layer(inputs=x,\n",
    "                                     num_filters=num_filters,\n",
    "                                     kernel_size=1,\n",
    "                                     strides=strides,\n",
    "                                     activation=None,\n",
    "                                     batch_normalization=False)\n",
    "                x = keras.layers.add([x, y])\n",
    "                x = Activation('relu')(x)\n",
    "            num_filters *= 2\n",
    "\n",
    "        # Add classifier on top.\n",
    "        # v1 does not use BN after last shortcut connection-ReLU\n",
    "        x = AveragePooling2D(pool_size=8)(x)\n",
    "        y = Flatten( )(x)\n",
    "        outputs = Dense(num_classes,\n",
    "                        activation='sigmoid',\n",
    "                        kernel_initializer='he_normal')(y)\n",
    "\n",
    "        # Instantiate model.\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    # ResNet V2 architecture\n",
    "    def resnet_v2(input_shape, depth, num_classes=num_classes):\n",
    "        if (depth - 2) % 9 != 0:\n",
    "            raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])')\n",
    "        # Start model definition.\n",
    "        num_filters_in = 16\n",
    "        num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "        # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "        x = inputs\n",
    "\n",
    "        # Instantiate the stack of residual units\n",
    "        for stage in range(3):\n",
    "            for res_block in range(num_res_blocks):\n",
    "                activation = 'relu'\n",
    "                batch_normalization = True\n",
    "                strides = 1\n",
    "                if stage == 0:\n",
    "                    num_filters_out = num_filters_in * 4\n",
    "                    if res_block == 0:  # first layer and first stage\n",
    "                        activation = None\n",
    "                        batch_normalization = False\n",
    "                else:\n",
    "                    num_filters_out = num_filters_in * 2\n",
    "                    if res_block == 0:  # first layer but not first stage\n",
    "                        strides = 2  # downsample\n",
    "\n",
    "                # bottleneck residual unit\n",
    "                y = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_in,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=activation,\n",
    "                                 batch_normalization=batch_normalization,\n",
    "                                 conv_first=False)\n",
    "                y = resnet_layer(inputs=y,\n",
    "                                 num_filters=num_filters_in,\n",
    "                                 conv_first=False)\n",
    "                y = resnet_layer(inputs=y,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 conv_first=False)\n",
    "                if res_block == 0:\n",
    "                    # linear projection residual shortcut connection to match\n",
    "                    # changed dims\n",
    "                    x = resnet_layer(inputs=x,\n",
    "                                     num_filters=num_filters_out,\n",
    "                                     kernel_size=1,\n",
    "                                     strides=strides,\n",
    "                                     activation=None,\n",
    "                                     batch_normalization=False)\n",
    "                x = keras.layers.add([x, y])\n",
    "\n",
    "            num_filters_in = num_filters_out\n",
    "\n",
    "        # Add classifier on top.\n",
    "        # v2 has BN-ReLU before Pooling\n",
    "        x = BatchNormalization( )(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = AveragePooling2D(pool_size=8)(x)\n",
    "        y = Flatten( )(x)\n",
    "        outputs = Dense(num_classes,\n",
    "                        activation='softmax',\n",
    "                        kernel_initializer='he_normal')(y)\n",
    "\n",
    "        # Instantiate model.\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    # Main function\n",
    "    if version == 2:\n",
    "        model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "    else:\n",
    "        model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opti(),\n",
    "                  metrics=['binary_accuracy'])\n",
    "\n",
    "    # Run training, with or without data augmentation.\n",
    "    if not data_augmentation:\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=32,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True,verbose=1)\n",
    "\n",
    "\n",
    "    from keras.utils.vis_utils import plot_model\n",
    "    plot_model(model, to_file='model_DRN1.pdf', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # Prediction.\n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    predict = []\n",
    "    for i in range(len(pred)):\n",
    "        if i == 0: predict.append(np.argmax(pred[i]))\n",
    "        else:\n",
    "            tem = []\n",
    "            for j in range(len(pred[i])):\n",
    "                tem.append(np.abs(pred[i][j] - pred[i - 1][j]))\n",
    "            predict.append(np.argmax(tem))\n",
    "\n",
    "    if len(np.unique(predict)) != nc:\n",
    "        for i in range(nc): prct[i]=i\n",
    "    return predict\n",
    "y_pred=classify(x_train, y_train, x_test, y_test)\n",
    "\n",
    "measures =main_perf_metrics_calc(y_test, y_pred,classes)\n",
    "print(measures)\n",
    "measures_table['Ride NN'] = measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f635ffe",
   "metadata": {},
   "source": [
    "# Showing All performance Measures for All Classifier in Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04cf6c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Classifier | Accuracy %  | Sensitivity | Specificity | Precision  | F1-Score  \n",
      "DNFN       | 93.443      | 0.95        | 0.905       | 0.95       | 0.95       \n",
      "NN         | 44.498      | 0.517       | 0.348       | 0.517      | 0.517      \n",
      "Ride NN    | 91.304      | 0.933       | 0.875       | 0.933      | 0.933      \n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def header():\n",
    "    for x in range(90):\n",
    "        print ('-',end = '')\n",
    "    print('')\n",
    "    \n",
    "header()\n",
    "print (\"{:<10} | {:<11} | {:<11} | {:<11} | {:<10} | {:<10}\".format('Classifier','Accuracy %', 'Sensitivity', 'Specificity','Precision','F1-Score'))\n",
    " \n",
    "# print each data item.\n",
    "for key, value in measures_table.items():\n",
    "    Acc,Sen,Spec,Prec,F1 = value\n",
    "#    header()\n",
    "    if key == 'GradientBoosting':\n",
    "        key ='Gradient'\n",
    "    print (\"{:<10} | {:<11} | {:<11} | {:<11} | {:<10} | {:<10} \".format(key,round(Acc*100,3),round(Sen,3),round(Spec,3),round(Prec,3),round(F1,3)))\n",
    "header()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22076cd0",
   "metadata": {},
   "source": [
    "# Saving Results to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5257f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Folder for Results if not exist\n",
    "if not os.path.exists('Results'):\n",
    "    os.makedirs('Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37841b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "                ## Using Pickle\n",
    "################################################        \n",
    "#import pickle\n",
    "# Open a file and use dump()\n",
    "#with open('results/NN.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "#    pickle.dump(measures_table, file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "148ff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "                ## Using CSV\n",
    "################################################\n",
    "# import csv\n",
    "#w = csv.writer(open(\"Results/NN.csv\", \"wb\"))\n",
    "\n",
    "# loop over dictionary keys and values\n",
    "#for key, val in measures_table.items():\n",
    "#    print(key,val)\n",
    "    # write every key and value to file\n",
    "#    w.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f2948fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "                ## Using JSON\n",
    "################################################\n",
    "# load json module\n",
    "# python dictionary with key value pairs\n",
    "\n",
    "# create json object from dictionary\n",
    "json = json.dumps(measures_table)\n",
    "\n",
    "# open file for writing, \"w\" \n",
    "f = open(\"Results/NN.json\",\"w\")\n",
    "\n",
    "# write json object to file\n",
    "f.write(json)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecbeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
